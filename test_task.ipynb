{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap.umap_ import UMAP\n",
    "from yellowbrick.cluster import kelbow_visualizer, silhouette_visualizer\n",
    "\n",
    "from utils import (\n",
    "    create_interactive_pie_charts,\n",
    "    plot_feature_correlations,\n",
    "    plot_feature_distributions,\n",
    "    detection_outlier\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"customer_data_test.csv\", sep=\";\", index_col=0)\n",
    "data = data.drop(columns=[\"ClientId\"])"
   ],
   "id": "b75cb82880b5db6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the first 5 rows of the data\n",
    "data.head()"
   ],
   "id": "a73c6359ff9e95fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data.info()"
   ],
   "id": "679b3620b024c227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()"
   ],
   "id": "badeb0fb157c259d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for duplicates\n",
    "data.duplicated().sum()"
   ],
   "id": "88ce3b46dbdde743",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for unique values\n",
    "data.nunique()"
   ],
   "id": "448e384dfc7f2861",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check negative values\n",
    "num_negative_features_per_col = (data < 0).sum()\n",
    "num_negative_features_per_col"
   ],
   "id": "59c1b9b9e459914a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop columns with negative values in columns TotalInactiveDays and ActivePassiveRatio\n",
    "columns_to_check = ['TotalInactiveDays', 'ActivePassiveRatio']\n",
    "negative_indices = data[columns_to_check].map(lambda x: x < 0).any(axis=1).index[data[columns_to_check].map(lambda x: x < 0).any(axis=1)]\n",
    "data = data.drop(negative_indices)"
   ],
   "id": "36a9c13ff31245ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Describe the data\n",
    "percentiles = [0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]\n",
    "data.describe(percentiles=percentiles)"
   ],
   "id": "159efdbf6cbf5341",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the most correlated features without duplicates\n",
    "corr_matrix = data.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "most_correlated = upper.stack().sort_values(ascending=False)\n",
    "most_correlated = most_correlated[most_correlated > 0.5]\n",
    "most_correlated"
   ],
   "id": "24b5d93d6ecf3f16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature analysis",
   "id": "3f6f5d50937e89fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data.describe(percentiles=percentiles)"
   ],
   "id": "9818f748d55e39aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_feature_correlations(data)"
   ],
   "id": "83d341667f9b0a3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_feature_distributions(data)"
   ],
   "id": "13ef22969ebb1606",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Binned features analysis\n",
    "create_interactive_pie_charts(data, num_bins=10)"
   ],
   "id": "ee312a01b3c4982e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data insights\n",
    "*Note: features that described days are changed to have a range between 0 and 365*\n",
    "\n",
    "- 29% of users won more than they lost\n",
    "- 82.3% of users have up to 34 active days per year\n",
    "- 47.1% of users have up to 37 days with deposits per year (it means that 47.4% of users have money only on activity days)\n",
    "- 72.4% of users have up to 587 days before their first deposit\n",
    "- 95.7% of users have up to 585 bets per year\n",
    "- 93.7% of users have up to 4 sport type of bets  \n",
    "- 97.1% of users have an average sports bet of up to 116 EUR"
   ],
   "id": "3b755530a657bc3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clustering",
   "id": "8ddde68dd72c5a33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "pca = PCA(n_components=scaled_data.shape[1])\n",
    "pca.fit(scaled_data)"
   ],
   "id": "3d22096c9ccab23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "3676be4eb5b3743e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_components_list = [0.8, 0.9]\n",
    "n_clusters_list = list()\n",
    "silhouette, calinski, davies = list(), list(), list()\n",
    "for n_components in n_components_list:\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X = pca.fit_transform(scaled_data)\n",
    "    print(\n",
    "        f\"Number of components for {n_components} explained variance: {pca.n_components_}\"\n",
    "    )\n",
    "    kmeans = KMeans(n_init=30, max_iter=1000)\n",
    "    visualizer_1 = kelbow_visualizer(kmeans, X, k=(2, 12))\n",
    "    kmeans = KMeans(n_clusters=visualizer_1.elbow_value_, n_init=30, max_iter=1000)\n",
    "    visualizer_2 = silhouette_visualizer(kmeans, X)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    n_clusters_list.append(visualizer_1.elbow_value_)\n",
    "    print(f\"Silhouette score: {silhouette_score(X, labels)}\")\n",
    "    print(f\"Calinski-Harabasz score: {calinski_harabasz_score(X, labels)}\")\n",
    "    print(f\"Davies-Bouldin score: {davies_bouldin_score(X, labels)}\\n\")\n",
    "\n",
    "n_clusters_list = np.unique(n_clusters_list).tolist()\n",
    "\n",
    "extended_n_cluster_list = []\n",
    "for n in n_clusters_list:\n",
    "    if n - 1 >= 2:  # Check to ensure no negative values\n",
    "        extended_n_cluster_list.append(n - 1)\n",
    "    extended_n_cluster_list.append(n)\n",
    "    extended_n_cluster_list.append(n + 1)\n",
    "\n",
    "# Remove duplicate values and sort the list\n",
    "n_clusters_list = sorted(list(set(extended_n_cluster_list)))"
   ],
   "id": "6d3de73acc7ee090",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the objective function for Optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    n_components = trial.suggest_categorical(\"pca__n_components\", n_components_list)\n",
    "    n_clusters = trial.suggest_categorical(\"kmeans__n_clusters\", n_clusters_list)\n",
    "    n_init = trial.suggest_categorical(\"kmeans__n_init\", [10, 20, 30])\n",
    "    max_iter = trial.suggest_categorical(\"kmeans__max_iter\", [300, 500, 1000])\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    preprocessing = Pipeline(\n",
    "        [(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=n_components))]\n",
    "    )\n",
    "\n",
    "    # Create pipeline\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"preprocessing\", preprocessing),\n",
    "            (\n",
    "                \"clusterer\",\n",
    "                KMeans(n_clusters=n_clusters, n_init=n_init, max_iter=max_iter),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe.fit(data)\n",
    "\n",
    "    return silhouette_score(\n",
    "        pipe.named_steps[\"preprocessing\"].transform(data),\n",
    "        pipe.named_steps[\"clusterer\"].labels_,\n",
    "    )\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    \"pca__n_components\": n_components_list,\n",
    "    \"kmeans__n_clusters\": n_clusters_list,\n",
    "    \"kmeans__n_init\": [10, 20, 30],\n",
    "    \"kmeans__max_iter\": [300, 500, 1000],\n",
    "}\n",
    "\n",
    "# Create a study for grid search\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", sampler=optuna.samplers.GridSampler(search_space)\n",
    ")\n",
    "n_experiments = np.prod([len(v) for v in search_space.values()])\n",
    "print(f\"Number of experiments: {n_experiments}\")\n",
    "study.optimize(objective, n_trials=n_experiments)\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", study.best_params)\n",
    "print(\"Best Silhouette Score: \", study.best_value)"
   ],
   "id": "7995e12cb953c9ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components=study.best_params[\"pca__n_components\"])\n",
    "X = pca.fit_transform(scaled_data)\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=study.best_params[\"kmeans__n_clusters\"],\n",
    "    n_init=study.best_params[\"kmeans__n_init\"],\n",
    "    max_iter=study.best_params[\"kmeans__max_iter\"],\n",
    ")"
   ],
   "id": "78ab822e15d9c064",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "visualizer_2 = silhouette_visualizer(kmeans, X)"
   ],
   "id": "d21dd0ab52ae394d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example creation of DataFrame for demonstration\n",
    "pca_components = pd.DataFrame(X)\n",
    "\n",
    "# Rename PCA components to PCA_1, PCA_2, etc.\n",
    "pca_components.columns = [f\"PCA_{i+1}\" for i in range(pca_components.shape[1])]\n",
    "\n",
    "# Initialize an empty DataFrame to store correlations\n",
    "correlation_matrix = pd.DataFrame(index=data.columns, columns=pca_components.columns)\n",
    "\n",
    "# Calculate correlations between each feature and each component\n",
    "for feature_column in data.columns:\n",
    "    for pca_column in pca_components.columns:\n",
    "        correlation_matrix.loc[feature_column, pca_column] = np.corrcoef(\n",
    "            data[feature_column], pca_components[pca_column]\n",
    "        )[0, 1]\n",
    "\n",
    "# Convert data to numeric format\n",
    "correlation_matrix = correlation_matrix.astype(float)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Original Features with PCA Components\")\n",
    "plt.show()"
   ],
   "id": "4646adeecd42ccee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessing = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=study.best_params[\"pca__n_components\"])),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        (\n",
    "            \"clusterer\",\n",
    "            KMeans(\n",
    "                n_clusters=study.best_params[\"kmeans__n_clusters\"],\n",
    "                n_init=study.best_params[\"kmeans__n_init\"],\n",
    "                max_iter=study.best_params[\"kmeans__max_iter\"],\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ],
   "id": "5091e22b2a6f1ee8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labels = pipe.fit_predict(data)\n",
    "data[\"label\"] = labels"
   ],
   "id": "936287456b1a07a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clusters analysis",
   "id": "843e7f269622692b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data.groupby(\"label\").describe(percentiles=percentiles).T"
   ],
   "id": "1b59dcde3c674eae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split features and cluster labels\n",
    "features = data.columns[:-1]  # Assuming the 22nd feature is the cluster number\n",
    "cluster_col = data.columns[-1]\n",
    "\n",
    "# Number of features\n",
    "num_features = len(features)\n",
    "\n",
    "# Define the number of rows and columns for subplots\n",
    "num_cols = 4\n",
    "num_rows = (num_features + num_cols - 1) // num_cols\n",
    "\n",
    "# Create subplots\n",
    "fig = sp.make_subplots(rows=num_rows, cols=num_cols, subplot_titles=features)\n",
    "\n",
    "# Generate box plots for each feature\n",
    "for i, feature in enumerate(features):\n",
    "    row = i // num_cols + 1\n",
    "    col = i % num_cols + 1\n",
    "    fig.add_trace(\n",
    "        px.box(data, x=cluster_col, y=feature).data[0],\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=num_rows * 400,\n",
    "    width=1000,\n",
    "    title_text=\"Box-Plots for Each Feature by Cluster\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "2f6248d151592616",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clusters visualization",
   "id": "aef87a79c50377a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the objective function for Optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    n_components = 2\n",
    "    n_neighbors = trial.suggest_int(\"n_neighbors\", 10, 200, step=10)\n",
    "    min_dist = trial.suggest_categorical(\n",
    "        \"min_dist\", np.arange(0.1, 1, 0.1).tolist() + [0.99]\n",
    "    )\n",
    "\n",
    "    reducer = UMAP(\n",
    "        n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist\n",
    "    )\n",
    "    embeddings = reducer.fit_transform(X)\n",
    "\n",
    "    return silhouette_score(embeddings, labels)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", study.best_params)\n",
    "print(\"Best Silhouette Score: \", study.best_value)"
   ],
   "id": "a8e5d91efc95fbcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reducer = UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=study.best_params[\"n_neighbors\"],\n",
    "    min_dist=study.best_params[\"min_dist\"],\n",
    ")\n",
    "embeddings = reducer.fit_transform(X)"
   ],
   "id": "2c354a8282850dfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scatter = plt.scatter(\n",
    "    embeddings[:, 0], embeddings[:, 1], c=labels, s=1, cmap=\"Spectral\"\n",
    ")\n",
    "legend1 = plt.legend(*scatter.legend_elements(), title=\"Labels\")\n",
    "plt.gca().add_artist(legend1)\n",
    "plt.xlabel(\"Embedding Dimension 1\")\n",
    "plt.ylabel(\"Embedding Dimension 2\")\n",
    "plt.title(\"Scatter Plot of Clusters\")\n",
    "plt.show()"
   ],
   "id": "db7d504a71e7ab9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ca86863986535063",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
